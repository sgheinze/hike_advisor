{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('hike_data_1_116.csv')\n",
    "df2=pd.read_csv('hike_data_2_180.csv')\n",
    "df3=pd.read_csv('hike_data_3_202.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = df1.append(df2).append(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hike_name', 'hike_difficulty', 'hike_distance', 'hike_elevation',\n",
       "       'hike_type', 'hike_tags', 'hike_description', 'user_names',\n",
       "       'user_hrefs', 'user_texts', 'user_ratings', 'user_dates'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime(row):\n",
    "    series = row['user_dates'].replace('datetime.datetime(' , '').replace('[', '').replace(']', '').replace(' ', '').replace(',0,0', '').split('),')\n",
    "    series[-1] = series[-1][:-1] \n",
    "    series = [ datetime.datetime.strptime(dt, \"%Y,%m,%d\") for dt in series ]\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts = df2['user_dates'][0].replace('datetime.datetime(' , '').replace('[', '').replace(']', '').replace(' ', '').replace(',0,0', '').split('),')\n",
    "dts[-1] = dts[-1][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [2019-01-19 00:00:00, 2019-01-13 00:00:00, 201...\n",
       "1      [2019-01-09 00:00:00, 2019-01-04 00:00:00, 201...\n",
       "2      [2019-01-19 00:00:00, 2019-01-16 00:00:00, 201...\n",
       "3      [2019-01-12 00:00:00, 2019-01-09 00:00:00, 201...\n",
       "4      [2019-01-09 00:00:00, 2019-01-03 00:00:00, 201...\n",
       "5      [2019-01-13 00:00:00, 2019-01-11 00:00:00, 201...\n",
       "6      [2019-01-11 00:00:00, 2019-01-02 00:00:00, 201...\n",
       "7      [2019-01-14 00:00:00, 2019-01-05 00:00:00, 201...\n",
       "8      [2019-01-18 00:00:00, 2019-01-11 00:00:00, 201...\n",
       "9      [2019-01-19 00:00:00, 2019-01-16 00:00:00, 201...\n",
       "10     [2019-01-19 00:00:00, 2019-01-13 00:00:00, 201...\n",
       "11     [2019-01-14 00:00:00, 2019-01-10 00:00:00, 201...\n",
       "12     [2019-01-16 00:00:00, 2019-01-05 00:00:00, 201...\n",
       "13     [2018-12-30 00:00:00, 2018-12-23 00:00:00, 201...\n",
       "14     [2018-12-31 00:00:00, 2018-12-29 00:00:00, 201...\n",
       "15     [2019-01-14 00:00:00, 2019-01-13 00:00:00, 201...\n",
       "16     [2019-01-20 00:00:00, 2018-12-24 00:00:00, 201...\n",
       "17     [2019-01-10 00:00:00, 2019-01-09 00:00:00, 201...\n",
       "18     [2019-01-19 00:00:00, 2019-01-08 00:00:00, 201...\n",
       "19     [2019-01-18 00:00:00, 2019-01-15 00:00:00, 201...\n",
       "20     [2019-01-05 00:00:00, 2019-01-02 00:00:00, 201...\n",
       "21     [2019-01-13 00:00:00, 2019-01-12 00:00:00, 201...\n",
       "22     [2019-01-15 00:00:00, 2019-01-14 00:00:00, 201...\n",
       "23     [2019-01-09 00:00:00, 2018-12-17 00:00:00, 201...\n",
       "24     [2019-01-13 00:00:00, 2019-01-11 00:00:00, 201...\n",
       "25     [2019-01-14 00:00:00, 2018-12-28 00:00:00, 201...\n",
       "26     [2019-01-19 00:00:00, 2019-01-19 00:00:00, 201...\n",
       "27     [2019-01-20 00:00:00, 2019-01-02 00:00:00, 201...\n",
       "28     [2019-01-14 00:00:00, 2019-01-06 00:00:00, 201...\n",
       "29     [2018-11-26 00:00:00, 2018-11-21 00:00:00, 201...\n",
       "                             ...                        \n",
       "87     [2019-01-08 00:00:00, 2018-12-27 00:00:00, 201...\n",
       "88     [2019-01-13 00:00:00, 2019-01-10 00:00:00, 201...\n",
       "89     [2019-01-15 00:00:00, 2018-12-01 00:00:00, 201...\n",
       "90     [2019-01-08 00:00:00, 2019-01-05 00:00:00, 201...\n",
       "91     [2019-01-05 00:00:00, 2018-12-31 00:00:00, 201...\n",
       "92     [2019-01-14 00:00:00, 2019-01-13 00:00:00, 201...\n",
       "93     [2019-01-11 00:00:00, 2019-01-07 00:00:00, 201...\n",
       "94     [2018-11-28 00:00:00, 2018-11-25 00:00:00, 201...\n",
       "95     [2018-12-28 00:00:00, 2018-12-11 00:00:00, 201...\n",
       "96     [2019-01-09 00:00:00, 2019-01-05 00:00:00, 201...\n",
       "97     [2019-01-07 00:00:00, 2019-01-05 00:00:00, 201...\n",
       "98     [2018-12-24 00:00:00, 2018-12-24 00:00:00, 201...\n",
       "99     [2018-11-24 00:00:00, 2018-11-06 00:00:00, 201...\n",
       "100    [2018-12-21 00:00:00, 2018-12-16 00:00:00, 201...\n",
       "101    [2019-01-13 00:00:00, 2019-01-12 00:00:00, 201...\n",
       "102    [2018-11-17 00:00:00, 2018-11-14 00:00:00, 201...\n",
       "103    [2018-11-19 00:00:00, 2018-11-19 00:00:00, 201...\n",
       "104    [2019-01-19 00:00:00, 2019-01-15 00:00:00, 201...\n",
       "105    [2019-01-02 00:00:00, 2018-12-16 00:00:00, 201...\n",
       "106    [2019-01-20 00:00:00, 2019-01-08 00:00:00, 201...\n",
       "107    [2019-01-14 00:00:00, 2019-01-11 00:00:00, 201...\n",
       "108    [2019-01-16 00:00:00, 2019-01-04 00:00:00, 201...\n",
       "109    [2019-01-12 00:00:00, 2019-01-06 00:00:00, 201...\n",
       "110    [2019-01-10 00:00:00, 2019-01-04 00:00:00, 201...\n",
       "111    [2018-12-01 00:00:00, 2018-11-25 00:00:00, 201...\n",
       "112    [2019-01-09 00:00:00, 2019-01-06 00:00:00, 201...\n",
       "113    [2019-01-06 00:00:00, 2019-01-02 00:00:00, 201...\n",
       "114    [2019-01-19 00:00:00, 2019-01-10 00:00:00, 201...\n",
       "115    [2019-01-16 00:00:00, 2018-12-25 00:00:00, 201...\n",
       "116    [2019-01-08 00:00:00, 2019-01-06 00:00:00, 201...\n",
       "Length: 117, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.apply(convert_datetime, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['hike_tags'] = total_df['hike_tags'].apply(literal_eval)\n",
    "total_df['user_names'] = total_df['user_names'].apply(literal_eval)\n",
    "total_df['user_hrefs'] = total_df['user_hrefs'].apply(literal_eval)\n",
    "total_df['user_texts'] = total_df['user_texts'].apply(literal_eval)\n",
    "total_df['user_ratings'] = total_df['user_ratings'].apply(literal_eval)\n",
    "total_df['user_dates'] = total_df.apply(convert_datetime, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dimensions(df):\n",
    "    total_vec = []\n",
    "    df.reset_index(inplace=True)\n",
    "    for index in range(len(df)):\n",
    "        len_vec = [ len(df.loc[index, 'user_names']),\n",
    "                    len(df.loc[index, 'user_hrefs']),\n",
    "                    len(df.loc[index, 'user_texts']),\n",
    "                    len(df.loc[index, 'user_ratings']),\n",
    "                    len(df.loc[index, 'user_dates'])\n",
    "                   ]\n",
    "        total_vec.append(len_vec)\n",
    "    \n",
    "    return total_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = check_dimensions(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dim:\n",
    "    check = dim_check.append(dim[0][0] == dim[0][1] == dim [0][2] == dim[0][3] == dim[0][4])\n",
    "    if check == False:\n",
    "        print('nooooo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.drop(labels='index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of hike_name is <class 'str'>\n",
      "Type of hike_difficulty is <class 'str'>\n",
      "Type of hike_distance is <class 'str'>\n",
      "Type of hike_elevation is <class 'str'>\n",
      "Type of hike_type is <class 'str'>\n",
      "Type of hike_tags is <class 'list'>\n",
      "Type of list is <class 'str'>\n",
      "Type of hike_description is <class 'str'>\n",
      "Type of user_names is <class 'list'>\n",
      "Type of list is <class 'str'>\n",
      "Type of user_hrefs is <class 'list'>\n",
      "Type of list is <class 'str'>\n",
      "Type of user_texts is <class 'list'>\n",
      "Type of list is <class 'str'>\n",
      "Type of user_ratings is <class 'list'>\n",
      "Type of list is <class 'int'>\n",
      "Type of user_dates is <class 'list'>\n",
      "Type of list is <class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "for column in total_df.columns:\n",
    "    column_type = str(type(total_df.loc[0, column]))\n",
    "    print('Type of ' + str(column) + ' is ' + column_type)\n",
    "    if column_type == \"<class 'list'>\":\n",
    "        print('Type of list is ' + str(type(total_df.loc[0, column][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.to_pickle('first_data_pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
